{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdO0NhFBG7ey"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import os\n",
        "import re \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91wUdeu8HILj"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KATuM_-FMy3T"
      },
      "outputs": [],
      "source": [
        "class StandardDataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    unique_id, feature, label = self.data[idx]\n",
        "    feature = np.float32(feature)\n",
        "    return (torch.FloatTensor(feature),\n",
        "            label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16HX8lS6Hv0a"
      },
      "outputs": [],
      "source": [
        "class SISA:\n",
        "  def __init__(self, full_data, n_shards, n_slices, model, n_classes):\n",
        "    \"\"\"\n",
        "    full_data: list of n sample <unique_id, sample_feature, sample_label>\n",
        "    n_shards: integer, number of shards\n",
        "    n_slices: integer, number of slices\n",
        "    model: string, architecture to use\n",
        "    keep_indices: list of k <= n sample of unique ids, use for filter unlearned samples\n",
        "    \"\"\"\n",
        "    self.full_data = full_data\n",
        "    self.n_shards = n_shards\n",
        "    self.n_slices = n_slices\n",
        "    self.n_classes = n_classes\n",
        "    self.model = model\n",
        "    self.n_samples = len(full_data)\n",
        "    self.sample2ss = []\n",
        "    for i in range(self.n_samples):\n",
        "      current_shard = random.sample(list(range(self.n_shards)), 1)[0]\n",
        "      current_slice = random.sample(list(range(self.n_slices)), 1)[0]\n",
        "      self.sample2ss.append([current_shard, current_slice])   \n",
        "    self.models =  [[None for j in range(self.n_slices)] for i in range(self.n_shards)]\n",
        "\n",
        "    #training configurations\n",
        "    self.batch_size = 16\n",
        "    self.epochs = 10\n",
        "\n",
        "  def _update(self, remove_ids):\n",
        "    #update self.sample2shard, remove_indices -> move to a new class\n",
        "    #update which shard to be re-trained, including slice step-point\n",
        "    #compatible to run before _train for unlearning task\n",
        "    unlearn_shard = self.n_shards + 1 # this shard does not exist before \n",
        "    removed_ss = []\n",
        "    for i in range(self.n_samples):\n",
        "      unique_id, feature, label = self.full_data[i]\n",
        "      if(unique_id in remove_ids):\n",
        "        removed_ss.append(self.sample2ss[i])\n",
        "        self.sample2ss[i] = [unlearn_shard, 0]\n",
        "\n",
        "    #figure out which shard to be re-trained / from which slice\n",
        "    retrain_shards = [False for _ in range(self.n_shards)]\n",
        "    retrain_slices = [self.n_slices-1 for _ in range(self.n_shards)] \n",
        "    for (retrain_shard, retrain_slice) in removed_ss:\n",
        "      retrain_shards[retrain_shard] = True\n",
        "      retrain_slices[retrain_shard] = min(retrain_slice, retrain_slices[retrain_shard])\n",
        "    return retrain_shards, retrain_slices\n",
        "\n",
        "  def _unlearn(self, retrain_shards, retrain_slices):\n",
        "    save_path = \"results_unlearned/\"\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    for i in range(self.n_shards):\n",
        "      if(retrain_shards[i]):\n",
        "        starting_slice = retrain_slices[i]\n",
        "        for j in range(starting_slice, self.n_slices):\n",
        "          self._train(i, j, self.batch_size, self.epochs, save_path=save_path, device=device)\n",
        "\n",
        "  def unlearn_do_all(self, remove_ids):\n",
        "    retrain_shards, retrain_slices = self._update(remove_ids)\n",
        "    print(\"Retrain Shards: \", retrain_shards)\n",
        "    print(\"Retrain Slices: \", retrain_slices)\n",
        "    self._unlearn(retrain_shards, retrain_slices)\n",
        "    print('Finish unlearning ...')\n",
        "\n",
        "  def learn_do_all(self):\n",
        "    save_path = \"results/\"\n",
        "    device = 'cuda' if torch.cida.is_available() else 'cpu'\n",
        "    for i in range(self.n_shards):\n",
        "      for j in range(self.n_slices):\n",
        "        self._train(i, j, self.batch_size, self.epochs, save_path=save_path, device=device)\n",
        "    print('Finish learning ...')\n",
        "\n",
        "  def _train(self, shard_num, slice_num, batch_size, epochs, device=\"cpu\", save_path=\"results/\", verbose=False):\n",
        "    #shard_num: integer, [0..n_shard-1]\n",
        "    #slice_num: integer, [0..n_slice-1]\n",
        "\n",
        "    #step 1: collect data given a shard and slice, put to dataloader\n",
        "    feature_dim = len(self.full_data[0][1])\n",
        "    data = []\n",
        "    for i in range(self.n_samples):\n",
        "      current_shard, current_slice = self.sample2ss[i]\n",
        "      if(current_shard == shard_num and current_slice == slice_num):\n",
        "        data.append(self.full_data[i])\n",
        "    dataset = StandardDataset(data)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size,shuffle=True)\n",
        "    \n",
        "    #step 2: train model\n",
        "    if(slice_num == 0 or not self.models[shard_num][slice_num-1]):\n",
        "      model = eval(self.model)(feature_dim ,self.n_classes) #intialize a new model\n",
        "    else:\n",
        "      model = self.models[shard_num][slice_num-1] #use previous slice ckpt\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    current_step = 0\n",
        "    for epoch in range(epochs):  \n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(dataloader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if(verbose):\n",
        "          # print statistics to make sure loss goes down\n",
        "          running_loss += loss.item()\n",
        "          current_step += 1\n",
        "          if (current_step % 200 == 0):    \n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch, current_step, running_loss / 200))\n",
        "            running_loss = 0.0\n",
        "    \n",
        "    #step 3: saving the model\n",
        "    outname = \"sh\"+str(shard_num)+\"sl\"+str(slice_num)+\".pt\"\n",
        "    PATH = os.path.join(save_path, outname)\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    #put model to SISA models\n",
        "    self.models[shard_num][slice_num] = model\n",
        "    print(\"Finish training ... Shard: \"+ str(shard_num) + \" Slice: \" + str(slice_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VTdBvNMPMKL",
        "outputId": "5c113899-e6a2-4acf-ece8-b60e186c9a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[181 5450 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 8 8 0.0 0.0 0.0 0.0 1.0 0.0\n",
            "  0.0 9 9 1.0 0.0 0.11 0.0 0.0 0.0 0.0 0.0]\n",
            " [239 486 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 8 8 0.0 0.0 0.0 0.0 1.0 0.0 0.0\n",
            "  19 19 1.0 0.0 0.05 0.0 0.0 0.0 0.0 0.0]\n",
            " [235 1337 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 8 8 0.0 0.0 0.0 0.0 1.0 0.0\n",
            "  0.0 29 29 1.0 0.0 0.03 0.0 0.0 0.0 0.0 0.0]\n",
            " [219 1337 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 6 6 0.0 0.0 0.0 0.0 1.0 0.0\n",
            "  0.0 39 39 1.0 0.0 0.03 0.0 0.0 0.0 0.0 0.0]\n",
            " [217 2032 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 6 6 0.0 0.0 0.0 0.0 1.0 0.0\n",
            "  0.0 49 49 1.0 0.0 0.02 0.0 0.0 0.0 0.0 0.0]] [b'normal.' b'normal.' b'normal.' b'normal.' b'normal.']\n"
          ]
        }
      ],
      "source": [
        "#Sample dataset\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_kddcup99\n",
        "data_all = fetch_kddcup99(download_if_missing=True)\n",
        "\n",
        "features = data_all.data[:, 4:]\n",
        "labels = data_all.target\n",
        "print(features[0:5], labels[0:5])\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "N, D = features.shape\n",
        "unique_ids = list(range(N))\n",
        "data = []\n",
        "for i in range(N):\n",
        "  data.append([unique_ids[i], features[i], labels[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXVh6RIFUhSU"
      },
      "outputs": [],
      "source": [
        "n_shards, n_slices = 5, 5\n",
        "model = \"Net\"\n",
        "n_classes = 23\n",
        "sisa = SISA(data, n_shards, n_slices, model, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6L3RzPFXDRa",
        "outputId": "27758170-ea38-4345-b734-a1f9cc7a01b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finish training ... Shard: 0 Slice: 0\n",
            "Finish training ... Shard: 0 Slice: 1\n",
            "Finish training ... Shard: 0 Slice: 2\n",
            "Finish training ... Shard: 0 Slice: 3\n",
            "Finish training ... Shard: 0 Slice: 4\n",
            "Finish training ... Shard: 1 Slice: 0\n",
            "Finish training ... Shard: 1 Slice: 1\n",
            "Finish training ... Shard: 1 Slice: 2\n",
            "Finish training ... Shard: 1 Slice: 3\n",
            "Finish training ... Shard: 1 Slice: 4\n",
            "Finish training ... Shard: 2 Slice: 0\n",
            "Finish training ... Shard: 2 Slice: 1\n",
            "Finish training ... Shard: 2 Slice: 2\n",
            "Finish training ... Shard: 2 Slice: 3\n",
            "Finish training ... Shard: 2 Slice: 4\n",
            "Finish training ... Shard: 3 Slice: 0\n",
            "Finish training ... Shard: 3 Slice: 1\n",
            "Finish training ... Shard: 3 Slice: 2\n",
            "Finish training ... Shard: 3 Slice: 3\n",
            "Finish training ... Shard: 3 Slice: 4\n",
            "Finish training ... Shard: 4 Slice: 0\n",
            "Finish training ... Shard: 4 Slice: 1\n",
            "Finish training ... Shard: 4 Slice: 2\n",
            "Finish training ... Shard: 4 Slice: 3\n",
            "Finish training ... Shard: 4 Slice: 4\n",
            "Finish learning ...\n"
          ]
        }
      ],
      "source": [
        "#learning on SISA\n",
        "sisa.learn_do_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtdsaZ-Lc6wt",
        "outputId": "0451bca9-0aec-430e-f3bd-6dc5961c9835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrain Shards:  [True, True, True, True, True]\n",
            "Retrain Slices:  [4, 1, 0, 1, 1]\n",
            "Finish training ... Shard: 0 Slice: 4\n",
            "Finish training ... Shard: 1 Slice: 1\n",
            "Finish training ... Shard: 1 Slice: 2\n",
            "Finish training ... Shard: 1 Slice: 3\n",
            "Finish training ... Shard: 1 Slice: 4\n",
            "Finish training ... Shard: 2 Slice: 0\n",
            "Finish training ... Shard: 2 Slice: 1\n",
            "Finish training ... Shard: 2 Slice: 2\n",
            "Finish training ... Shard: 2 Slice: 3\n",
            "Finish training ... Shard: 2 Slice: 4\n",
            "Finish training ... Shard: 3 Slice: 1\n",
            "Finish training ... Shard: 3 Slice: 2\n",
            "Finish training ... Shard: 3 Slice: 3\n",
            "Finish training ... Shard: 3 Slice: 4\n",
            "Finish training ... Shard: 4 Slice: 1\n",
            "Finish training ... Shard: 4 Slice: 2\n",
            "Finish training ... Shard: 4 Slice: 3\n",
            "Finish training ... Shard: 4 Slice: 4\n",
            "Finish unlearning ...\n"
          ]
        }
      ],
      "source": [
        "#unlearning on SISA\n",
        "n_requests = 15\n",
        "remove_ids = random.sample(unique_ids, n_requests)\n",
        "sisa.unlearn_do_all(remove_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by_SAP2KeRAl"
      },
      "outputs": [],
      "source": [
        "class SISA_inference:\n",
        "  \"\"\"\n",
        "  this class do the \"Aggregation\" in SISA\n",
        "  majority voting and return accuracy\n",
        "  \"\"\"\n",
        "  def __init__(self, test_data, n_shards, n_slices, model, n_classes, learning_path, unlearning_path=None):\n",
        "    \"\"\"\n",
        "    full_data: list of n sample <unique_id, sample_feature, sample_label>\n",
        "    if unlearning_path is None, inference before unlearning\n",
        "    if unlearning path is None, inference after unlearning\n",
        "    \"\"\"\n",
        "    self.test_data = test_data\n",
        "    self.n_shards = n_shards\n",
        "    self.n_slices = n_slices\n",
        "    self.n_classes = n_classes\n",
        "    self.model = model\n",
        "    self.n_samples = len(test_data) \n",
        "    self.feature_dim = len(self.test_data[0][1])\n",
        "    self.batch_size = 8\n",
        "    self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    #loading models' checkpoints\n",
        "    self.models =  [None for _ in range(self.n_shards)]\n",
        "    if(unlearning_path):\n",
        "      for model_name in os.listdir(unlearning_path):\n",
        "        current_shard, current_slice = re.findall(r'\\d+', model_name)\n",
        "        #if not the last slice, skip the model\n",
        "        if(int(current_shard) >= self.n_shards or int(current_slice) < self.n_slices - 1):\n",
        "          continue\n",
        "        saved_path = os.path.join(unlearning_path, model_name)\n",
        "        model = eval(self.model)(self.feature_dim ,self.n_classes)\n",
        "        model.load_state_dict(torch.load(saved_path))\n",
        "        model.to(self.device)\n",
        "        model.eval()\n",
        "        self.models[int(current_shard)] = model\n",
        "\n",
        "    #load learning models\n",
        "    for model_name in os.listdir(learning_path):\n",
        "      current_shard, current_slice = re.findall(r'\\d+', model_name)\n",
        "      if(int(current_shard) >= self.n_shards or self.models[int(current_shard)]): #loaded unlearned models\n",
        "        continue \n",
        "      #if not the last slice, skip the model\n",
        "      if(int(current_slice) < self.n_slices - 1):\n",
        "        continue\n",
        "      saved_path = os.path.join(learning_path, model_name)\n",
        "      model = eval(self.model)(self.feature_dim ,self.n_classes)\n",
        "      model.load_state_dict(torch.load(saved_path))\n",
        "      model.to(self.device)\n",
        "      model.eval()\n",
        "      self.models[int(current_shard)] = model  \n",
        "\n",
        "\n",
        "    #assert that all models are loaded\n",
        "    assert None not in self.models\n",
        "    print(\"All contituent models loaded ...\")\n",
        "\n",
        "  def inference(self):\n",
        "    #create dataloader\n",
        "    dataset = StandardDataset(self.test_data)\n",
        "    dataloader = DataLoader(dataset, batch_size=self.batch_size,shuffle=False)\n",
        "\n",
        "    true_labels, predicted_labels = [], []\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(dataloader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "        B = inputs.size(0)\n",
        "        outputs = torch.zeros((B, self.n_classes), device=self.device)\n",
        "        for j in range(self.n_shards):\n",
        "            outputs += self.models[j](inputs)\n",
        "        y_pred = list(outputs.argmax(dim=-1).detach().cpu().numpy())\n",
        "        y_true = list(labels.detach().cpu().numpy())\n",
        "        \n",
        "        predicted_labels += y_pred\n",
        "        true_labels += y_true\n",
        "    return true_labels, predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEPHmjKrhi8O",
        "outputId": "4b745451-2001-4e75-ca68-c12130884775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All contituent models loaded ...\n"
          ]
        }
      ],
      "source": [
        "#prediction on the original trained models (no unlearning done)\n",
        "#prediction on the training set (did not split train/test before)\n",
        "sisa_inference = SISA_inference(test_data=data,\n",
        "                                n_shards=5,\n",
        "                                n_slices=5,\n",
        "                                model=\"Net\",\n",
        "                                n_classes=n_classes,\n",
        "                                learning_path = \"results/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhNvFjcShv9D",
        "outputId": "4191a054-1864-422e-ba6f-d3af834b4005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score:  0.9946459765880398\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_true, y_pred = sisa_inference.inference()\n",
        "print(\"Accuracy Score: \", accuracy_score(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xiz4GbelG_j",
        "outputId": "d5128f37-0367-4ac3-f1e5-491eb32fc376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All contituent models loaded ...\n"
          ]
        }
      ],
      "source": [
        "#prediction on the original unlearned models (no unlearning done)\n",
        "#prediction on the training set (did not split train/test before)\n",
        "sisa_inference = SISA_inference(test_data=data,\n",
        "                                n_shards=5,\n",
        "                                n_slices=5,\n",
        "                                model=\"Net\",\n",
        "                                n_classes=n_classes,\n",
        "                                learning_path = \"results/\",\n",
        "                                unlearning_path = \"results_unlearned/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOV3AWw4m-Tc",
        "outputId": "ed0ba5d0-a3cc-4d67-9058-885dd4858c20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score:  0.9957775074338945\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_true, y_pred = sisa_inference.inference()\n",
        "print(\"Accuracy Score: \", accuracy_score(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7X5LOV4nN7s"
      },
      "outputs": [],
      "source": [
        "#Baseline training and re-training from scratch\n",
        "#set num_shards = 1 and num_slices = 1\n",
        "n_shards, n_slices = 1, 1\n",
        "model = \"Net\"\n",
        "n_classes = 23\n",
        "sisa_baseline = SISA(data, n_shards, n_slices, model, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z6jq4uXGuih",
        "outputId": "efb61737-8588-47f3-e5d6-36c07bb499bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finish training ... Shard: 0 Slice: 0\n",
            "Finish learning ...\n"
          ]
        }
      ],
      "source": [
        "#learning on SISA baseline\n",
        "sisa_baseline.learn_do_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyE_u0DtG07F",
        "outputId": "5aa727c5-5970-41ce-9489-236fedfcfa12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrain Shards:  [True]\n",
            "Retrain Slices:  [0]\n",
            "Finish training ... Shard: 0 Slice: 0\n",
            "Finish unlearning ...\n"
          ]
        }
      ],
      "source": [
        "#unlearning on SISA baseline, same remove_ids as SISA from above\n",
        "sisa_baseline.unlearn_do_all(remove_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8ScXlFYIr70",
        "outputId": "7a19b0ef-9301-4ef6-89a9-b5be6dc5cd37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All contituent models loaded ...\n",
            "Accuracy Score:  0.9949273411454169\n"
          ]
        }
      ],
      "source": [
        "sisa_inference_baseline = SISA_inference(test_data=data,\n",
        "                                n_shards=1,\n",
        "                                n_slices=1,\n",
        "                                model=\"Net\",\n",
        "                                n_classes=n_classes,\n",
        "                                learning_path = \"results/\")\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_true, y_pred = sisa_inference_baseline.inference()\n",
        "print(\"Accuracy Score: \", accuracy_score(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9FAAyYiI78o",
        "outputId": "aea5df70-bfd7-4b39-f8d4-e6f5c7bc6f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All contituent models loaded ...\n",
            "Accuracy Score:  0.9977652771845731\n"
          ]
        }
      ],
      "source": [
        "sisa_inference_baseline = SISA_inference(test_data=data,\n",
        "                                n_shards=1,\n",
        "                                n_slices=1,\n",
        "                                model=\"Net\",\n",
        "                                n_classes=n_classes,\n",
        "                                learning_path = \"results/\",\n",
        "                                unlearning_path = \"results_unlearned/\")\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_true, y_pred = sisa_inference_baseline.inference()\n",
        "print(\"Accuracy Score: \", accuracy_score(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJqwzg2TMPeB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SISA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
